# 中国政府采购网招标公告爬虫

## 📋 项目概述
本项目是一个用于自动抓取中国政府采购网 (`http://www.ccgp.gov.cn`) 招标公告数据的 Python 爬虫。它能够获取最新的招标信息，并进行筛选、去重，最终通过邮件通知用户，并将结果保存为 Excel 文件。

## ✨ 主要功能
- 🔄 **自动数据抓取**: 默认抓取最近3天的招标公告数据。
- 🔍 **智能去重**: 基于历史数据中的公告名称，自动过滤重复数据，只报告新公告。
- 📊 **Excel 导出**: 将新发现的公告数据生成带有时间戳的 Excel 文件，方便归档和分析。
- 📧 **邮件通知**: 当发现新公告时，自动发送格式精美的 HTML 邮件提醒。
- ⏸️ **中断保护**: 支持使用 `Ctrl+C` 安全中断程序，并自动保存已抓取的数据，防止数据丢失。

## 🛠️ 环境要求
- Python 3.8+
- 依赖库：见 `requirements.txt` 文件。

## 🚀 快速开始

### 1. 安装依赖
在项目根目录下打开命令行工具，运行以下命令来安装所有必需的 Python 库：
```bash
pip install -r requirements.txt
```

### 2. 配置邮件发送服务
打开 `Integrated(verion=1.2).py` 文件，找到开头的配置区域，修改以下邮件服务器信息。
**请务必填写真实有效的信息，否则邮件通知功能将无法使用。**

```python
# ------------------------- 配置文件 -------------------------
# 邮件服务器配置
SMTP_SERVER = "smtp.example.com"  # SMTP服务器地址 (例如: smtp.qq.com)
SMTP_PORT = 465                   # SMTP SSL端口 (例如: 465)
SENDER_EMAIL = "sender@example.com"   # 发件邮箱地址
SENDER_PASSWORD = "your_password"     # 发件邮箱的授权码或密码
RECEIVER_EMAIL = "receiver@example.com" # 收件邮箱地址
```

基础URL为: `https://search.ccgp.gov.cn/bxsearch`

**查询参数 (Query Parameters):**

| 参数 | 描述 | 示例值 | 备注 |
| :--- | :--- | :--- | :--- |
| `searchtype` | 搜索类型 | `1` | 固定值 |
| `page_index` | 页码 | `1`, `2`, `3`, ... | 用于分页 |
| `bidSort` | 公告类别 | `0` (所有), `1` (中央), `2` (地方) | |
| `buyerName` | 采购人名称 | (字符串) | |
| `projectId` | 项目ID | (字符串) | |
| `pinMu` | 品目 | `0` (所有), `1` (货物类) | |
| `bidType` | 公告类型 | `0` (所有), `1` (公开招标), `2` (询价), `11` (成交公告) | |
| `dbselect` | 数据库选择 | `bidx` | 固定值 |
| `kw` | 关键字 | (字符串) | |
| `start_time` | 开始时间 | `2025%3A06%3A30` | URL编码格式 `YYYY:MM:DD` |
| `end_time` | 结束时间 | `2025%3A07%3A07` | URL编码格式 `YYYY:MM:DD` |
| `timeType` | 时间类型 | `2` (近一周), `0` (今天), `1` (近三日) | |
| `displayZone`| 显示区域 | `广西` | URL编码的地区名称 |
| `zoneId` | 区域ID | `45` | |
| `pppStatus` | PPP项目状态 | `0` | |
| `agentName` | 代理机构名称 | (字符串) | |

### 3. 运行爬虫
配置完成后，在命令行中运行主程序：
```bash
python "Integrated(verion=1.2).py"
```
程序将开始抓取数据。如果发现新公告，会发送邮件并生成 Excel 文件。

## 📝 实现逻辑

1.  **数据抓取**: 程序访问中国政府采购网，搜索并抓取过去3天的公告列表。
2.  **历史数据加载**: 程序会尝试读取名为 `existing_data.xlsx` 的文件，将其中已有的公告标题作为历史记录。
3.  **数据去重**: 将新抓取到的数据与历史记录进行比对，筛选出标题不重复的新公告。
4.  **结果处理**:
    - 如果没有新公告，程序将提示 "未发现新数据"。
    - 如果有新公告，程序会：
        - 调用邮件服务，发送一封包含所有新公告详情的 HTML 表格邮件。
        - 将新公告数据保存到一个以 `filtered_data_` 开头并附带当前时间戳的 Excel 文件中。
5.  **更新历史数据 (手动)**: 为了实现下一次运行时能正确去重，您可以将本次生成的 `filtered_data_...xlsx` 文件**重命名**为 `existing_data.xlsx`，替换掉旧的同名文件。

## ⚠️ 注意事项
- **依赖库**: `requirements.txt` 中包含了 `selenium` 和 `beautifulsoup4`，但当前版本的脚本 (`v1.2`) 使用的是 `requests` 和 `lxml` 进行数据抓取，并未实际使用前两者。
- **中断操作**: 在程序运行期间，您可以随时按下 `Ctrl+C` 来中断它。程序会自动将当前已抓取到的数据保存到 `interrupted_data_...xlsx` 文件中，确保您的进度不会丢失。
- **网络策略**: 脚本内置了随机延迟（2-6秒）和模拟浏览器请求头的功能，以降低被目标网站封禁的风险。请勿过于频繁地运行此脚本。
  
1. **合规使用**: 仅供学习研究使用，请遵守网站robots.txt协议
2. **频率控制**: 建议每日运行不超过3次，避免给服务器造成压力
3. **数据安全**: 请妥善保管邮箱授权码等敏感信息
4. **网络环境**: 确保网络连接稳定，避免抓取过程中断

## 🐛 常见问题

### Q: 程序报错 "找不到数据总数"
A: 可能是网站结构变化或网络问题，请检查网络连接或稍后重试。

### Q: 邮件发送失败
A: 检查邮箱配置是否正确，确认使用授权码而非登录密码。

### Q: 抓取的数据为空
A: 检查时间范围设置，可能该时间段内没有新公告。

---

## 📄 免责声明
本程序仅供个人学习、研究和技术实验使用。使用者应确保符合目标网站的使用条款及相关法律法规，开发者不承担因使用本程序产生的任何法律责任。
